{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "382105c1-a555-4f26-bd6c-24d606d417f8",
   "metadata": {},
   "source": [
    "# Python Dictionaries, A very clever data structure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52897901-6615-474f-bc6c-225493907c6f",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "talk = {\n",
    "    \"title\": \"Python Dictionaries, A very clever data structure!\",\n",
    "    \"author\": \"Kai Striega\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dec3da-c63e-48d1-a7ef-cd64b9496bbc",
   "metadata": {},
   "source": [
    "# What is a dictionary (Revision)\n",
    "\n",
    "A dictionary is a mapping of ``(key, value)`` pairs. Unlike sequences, which are index by integers, dictionaries are indexed by _keys_. The key can be any hashable Python object. \n",
    "\n",
    "\n",
    "## Importance\n",
    "\n",
    "Dictionaries play an extremely important role in Python. Not only are dictionaries used in almost every python program, the Python interpreter also requires dictionaries to _run_ the Python code.\n",
    "\n",
    "## Operations\n",
    "\n",
    "There are many operations that can be performed on dictionaries. The full list is available in the [docs](https://docs.python.org/3/library/stdtypes.html#dict). For the sake of brevity our dictionary will be defined as having three main operations:\n",
    "\n",
    "* Insert new items ``d[k] = v``\n",
    "* Lookup the value of a give key ``d[k]``\n",
    "* Delete a ``(key, value)`` pair from the dictionary ``del d[k]``\n",
    "\n",
    "We can verify with our example dictionary from above that we can do all these operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22de7f94-49d2-41d3-a353-c1bdde1fee91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Python Dictionaries, A very clever data structure!',\n",
       " 'author': 'Kai Striega',\n",
       " 'audience': 'SheCodes'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ``d[k] = v`` adds the ``(k, v)`` pair to the dictionary\n",
    "talk[\"audience\"] = \"SheCodes\"\n",
    "# We can see our dict now contains an ``audience`` key and ``SheCodes`` value\n",
    "talk  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4ffe453-e841-4de4-b365-0864e976cf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kai Striega'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ``d[k]`` returns the value assoicated with ``k``\n",
    "talk[\"author\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b6ad17-8a18-48ea-b0d2-2dbb19b8dc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Kai Striega', 'audience': 'SheCodes'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ``del d[k]`` delets the value associated with ``k``\n",
    "del talk[\"title\"]\n",
    "talk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2720aad5-675f-4029-aa86-3d88fc723bb1",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "## Implementation vs Interface\n",
    "\n",
    "Dictionaries are an _interface_. It defines how an object should behave given different operations. There are several ways to _implement_ this interface:\n",
    "\n",
    "* A [Hashmap/Hash table](https://en.wikipedia.org/wiki/Hash_table)\n",
    "* A [Linked List](https://en.wikipedia.org/wiki/Linked_list) with linear search for the elements\n",
    "* A [Search Tree](https://en.wikipedia.org/wiki/Search_tree)\n",
    "\n",
    "Python chooses to implement using a hashmap. This allows for very perfomant _average case_ operations. This talk covers how to implement a dictionary using a hashmap, and the optimisations that Python uses to increase their performance.\n",
    "\n",
    "## Objective\n",
    "\n",
    "A computer doesn't understand complex data structures such as dictionaries, lists or tuples. All of these complex data structures had to be written by someone. In the rest of this talk we will implement a hashmap from scratch. Using only what the computer has given us. CPython does this for dictionaries in about [5000 lines of C](https://github.com/python/cpython/blob/3.12/Objects/dictobject.c), however we'll be working in Python using some abstractions.\n",
    "\n",
    "## And first, there was memory\n",
    "\n",
    "To begin our hashmap we will need to get some memory. As we haven't put anything into it yet, let's represent it as a list of ``None`` objects. For now I've chosen to store 8 ``None`` objects. This is a very small amount of memory. Don't worry - we'll figure out how to add more items later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6db3034-beae-412e-adb7-7cc684d838c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mimick 8 \"slots\" in memory\n",
    "memory = [None] * 8\n",
    "memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe4fe9c-95ef-414c-a69f-c9e0be556be3",
   "metadata": {},
   "source": [
    "## Hashing\n",
    "\n",
    "Now we have some memory to work with, and we can access our memory using an index.  But that isn't what we want to do. We want to be able to use some key to access the underlying value. To do this we will use what's called a [Hash Function](https://en.wikipedia.org/wiki/Hash_function).\n",
    "\n",
    "A hash function takes arbitrarily large data and converts it to fixed size data. We can then interperate that bit pattern as an integer and use that integer as an index. Designing good hash functions is difficult (more on that later), luckily Python has an inbuilt hash function - [hash](https://docs.python.org/3/library/functions.html#hash). Let's play around with hash for a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625a3044-fca1-4ca6-be41-7e6604f68051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97bd686d-a85c-4b28-b8b2-fb5a2f19f5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6051908547441681576"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(\"SheCodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42eadb75-e3a7-4dea-96ec-0a8cd19231e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1218130345949401146"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash((10, \"SheCodes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb04b5-d1da-471d-bb99-8de44f83760a",
   "metadata": {},
   "source": [
    "These integers are far too large to fit into our small hashtable. But we can take the modulus of the integer to get our index. This way we will always find a way to store the given key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a34b47-9dd3-4563-825a-6f0fdcbc209f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash(\"SheCodes\") % 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad73dcae-40ad-41a2-86a8-a11c876b9b3e",
   "metadata": {},
   "source": [
    "In a hashmap, each entry is refered to as a bucket. Let's create a quick class to store each bucket in our memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c97707f8-c495-4b4f-bf4b-a3794f63976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Hashable, Any\n",
    "\n",
    "@dataclass\n",
    "class Bucket:\n",
    "    key: Hashable\n",
    "    value: Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b8c093-5a28-499e-8e4f-890fd06e6dae",
   "metadata": {},
   "source": [
    "Now we may assign a ``(key, value)`` pair by creating a bucket and assigning it to the memory address we calculated using the hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f663f54-2941-45cc-b98d-6f0440fadf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"Kai\"\n",
    "value = \"is awesome\"\n",
    "\n",
    "h = hash(key)\n",
    "i = h % 8\n",
    "memory[i] = Bucket(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f47be9-d7c4-4685-8546-60eddf781dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key='Kai', value='is awesome'),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e3b3517-bb59-44bd-b883-ea7a7d938d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bucket(key='Kai', value='is awesome')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c0e71-74e2-4aae-b92a-a3c187df7613",
   "metadata": {},
   "source": [
    "## Wrapping it all into a class\n",
    "\n",
    "We've done quite a bit of work here. We've found a way to mimick allocating memory, assing objects to our \"dictionary\" and to access objects. Let's wrap it all in a class so that we can reuse our dictionary more easily "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "445ea969bbc932d2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "class Dictionary:\n",
    "\n",
    "    def __init__(self, init_size=8):\n",
    "        self._size = init_size\n",
    "        self._data: list[Optional[Bucket]] = [None] * self._size\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        h = hash(key)\n",
    "        i = h % self._size\n",
    "        bucket = Bucket(key, value)\n",
    "        self._data[i] = bucket\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        h = hash(item)\n",
    "        i = h % self._size\n",
    "        return self._data[i].value "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd2cf4769389c3a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "That's better. Let's experiment with our new class a bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89843aff062eeea4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key=0, value='Kai'),\n",
       " Bucket(key=1, value='is awesome'),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Dictionary()\n",
    "d[0] = \"Kai\"\n",
    "d[1] = \"is awesome\"\n",
    "d._data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3c5295e66fbca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3394433a8b3e458",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key=8, value='SheCodes'),\n",
       " Bucket(key=1, value='is awesome'),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[8] = \"SheCodes\"\n",
    "d._data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cff0dcd-4f79-489d-ba40-9ad8964be7ba",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "What's happened here?\n",
    "\n",
    "Because ``hash(0) % 8 == hash(8) % 8`` the index is the same, so we've overwritten the existing data in our dictionary. This is called a [collision](https://en.wikipedia.org/wiki/Hash_table#Collision_resolution). There are two common ways of resolving collisions: Separate Chaining and Open Addressing\n",
    "\n",
    "### Separate Chaining\n",
    "\n",
    "![chaining](static/images/hash_table_with_chaining.png)\n",
    "\n",
    "### Open Addressing\n",
    "\n",
    "The problem with chaining is that we're allocating more memory than we need to. What if, instead of allocating new memory, we use the memory we have already assigned? It's possible to do this by storing the ``(key, value)`` pairs in exisitng buckets, then instead of generating an index using our hash we generate a _sequence_ of indecies. This process is called _probing_ and the sequence we generate is called a _probe sequence_. To add a new item to our dictionary we check each index generated by the probe sequence and assign it to the first empty slot. There are three common types of prove sequences, which we'll explore now!\n",
    "\n",
    "#### Linear Probing\n",
    "\n",
    "$$ probes[i] = hash(key) + i \\space \\% \\space number \\space of \\space buckets$$\n",
    "\n",
    "#### Quadratic Probing\n",
    "\n",
    "$$ probes[i] = hash(key) + a * i + b * i^2 \\space \\% \\space number \\space of \\space buckets $$ \n",
    "\n",
    "#### Pseudo-Random Probing\n",
    "\n",
    "$$ probes[i] = a * probes[i-1] + c \\space \\% \\space number \\space of \\space buckets $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "806a1c5dd9e51b08",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def probes(hash_value, hash_table_size):\n",
    "    mask = hash_table_size - 1 # used to take modulus fast\n",
    "    perturb = hash_value # used to perturb the probe sequence\n",
    "    probe = hash_value & mask\n",
    "\n",
    "    while True:\n",
    "        yield probe\n",
    "\n",
    "        perturb >>= 5\n",
    "        probe = (probe * 5 + perturb + 1) & mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09934db4-4728-4988-802a-81f2fbb54ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "\n",
    "    def __init__(self, init_size=8):\n",
    "        self._size = init_size\n",
    "        self._data: list[Optional[Bucket]] = [None] * self._size\n",
    "                \n",
    "    def _probes(self, hash_value):\n",
    "        mask = self._size - 1 # used to take modulus fast\n",
    "        perturb = hash_value # used to perturb the probe sequence\n",
    "        probe = hash_value & mask\n",
    "    \n",
    "        while True:\n",
    "            yield probe\n",
    "    \n",
    "            perturb >>= 5\n",
    "            probe = (probe * 5 + perturb + 1) & mask\n",
    "        \n",
    "        \n",
    "    def __setitem__(self, key, value):\n",
    "        h = hash(key)\n",
    "        bucket = Bucket(key, value)\n",
    "        \n",
    "        for probe in self._probes(h):\n",
    "            if self._data[probe] is None:\n",
    "                self._data[probe] = bucket\n",
    "                break\n",
    "            elif self._data[probe].key == bucket.key:\n",
    "                self._data[probe] = bucket\n",
    "                break\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        h = hash(item)\n",
    "        for probe in self._probes(h):\n",
    "            if self._data[probe] is None:\n",
    "                raise KeyError(item)\n",
    "            elif self._data[probe].key == item:\n",
    "                return self._data[probe].value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5226e08-8a30-4fbe-b849-39c645249938",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dictionary()\n",
    "d[0] = \"Kai\"\n",
    "d[1] = \"is awesome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa109984-0e40-416b-9883-70ceab50217c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key=0, value='Kai'),\n",
       " Bucket(key=1, value='is awesome'),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a74f139-9e4e-4782-bdc0-4d26dc08d758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key=0, value='Kai'),\n",
       " Bucket(key=1, value='is awesome'),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " Bucket(key=8, value='SheCodes'),\n",
       " None]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[8] = \"SheCodes\"\n",
    "d._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "267e4b80-94ff-4c89-9445-14597ea97bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key=0, value='Not Kai'),\n",
       " Bucket(key=1, value='is awesome'),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " Bucket(key=8, value='SheCodes'),\n",
       " None]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0] = \"Not Kai\"\n",
    "d._data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9bf370-39d8-41ab-afdd-67cafe963537",
   "metadata": {},
   "source": [
    "## Reshaping\n",
    "\n",
    "So far we've been dealing with a fixed size of 8 buckets in a dictionary. This works well but what if we want to store more than 8 buckets? One solution would be to create a bigger, fixed size, dictionary. But Python uses many small dictionaries, so increasing the size would lead to a lot of empty (wasted) buckets. What we're going to do instead is to dynamically reshape our buckets.\n",
    "\n",
    "### Load Factor\n",
    "\n",
    "### Choosing a sizing scheme\n",
    "\n",
    "#### Primes\n",
    "\n",
    "#### Powers of 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18832f8d-743a-4b3f-9f34-c5449aab317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "\n",
    "    def __init__(self, init_size=8):\n",
    "        self._items = 0\n",
    "        self._size = init_size\n",
    "        self._data: list[Optional[Bucket]] = [None] * self._size\n",
    "        self._reshape_threshold = 2/3\n",
    "\n",
    "    @property\n",
    "    def load_factor(self):\n",
    "        return self._items / self._size\n",
    "        \n",
    "        \n",
    "    def _probes(self, hash_value):\n",
    "        mask = self._size - 1 # used to take modulus fast\n",
    "        perturb = hash_value # used to perturb the probe sequence\n",
    "        probe = hash_value & mask\n",
    "    \n",
    "        while True:\n",
    "            yield probe\n",
    "    \n",
    "            perturb >>= 5\n",
    "            probe = (probe * 5 + perturb + 1) & mask\n",
    "        \n",
    "\n",
    "    def _reshape(self):\n",
    "        self._size <<= 1\n",
    "        new_buckets = [None] * self._size\n",
    "        for bucket in self._data:\n",
    "            if bucket: # Avoid copying empty buckets\n",
    "                h = hash(bucket.key)\n",
    "                for probe in self._probes(h):\n",
    "                    if new_buckets[probe] is None:\n",
    "                        new_buckets[probe] = bucket\n",
    "                        break\n",
    "        self._data = new_buckets\n",
    "        \n",
    "    def __setitem__(self, key, value):\n",
    "        h = hash(key)\n",
    "        bucket = Bucket(key, value)\n",
    "        \n",
    "        for probe in self._probes(h):\n",
    "            if self._data[probe] is None:\n",
    "                self._data[probe] = bucket\n",
    "                self._items += 1\n",
    "                break\n",
    "            elif self._data[probe].key == bucket.key:\n",
    "                self._data[probe] = bucket\n",
    "                break\n",
    "\n",
    "        if self.load_factor > self._reshape_threshold:\n",
    "            self._reshape()\n",
    "            \n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        h = hash(item)\n",
    "        for probe in self._probes(h):\n",
    "            if self._data[probe] is None:\n",
    "                raise KeyError(item)\n",
    "            elif self._data[probe].key == item:\n",
    "                return self._data[probe].value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "801011d1-087c-4f7a-bf04-49010286c6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key=0, value=0),\n",
       " Bucket(key=1, value=1),\n",
       " Bucket(key=2, value=2),\n",
       " Bucket(key=3, value=3),\n",
       " Bucket(key=4, value=4),\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Dictionary()\n",
    "for i in range(5):\n",
    "    d[i] = i\n",
    "d._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f40730a-8232-4c65-b657-530d8665573f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key=0, value=15),\n",
       " Bucket(key=1, value=1),\n",
       " Bucket(key=2, value=2),\n",
       " Bucket(key=3, value=3),\n",
       " Bucket(key=4, value=4),\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can update values without resizing\n",
    "d[0] = 15\n",
    "d._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1255d20e-b4f2-4354-9971-cc7a9bc5bd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key=0, value=15),\n",
       " Bucket(key=1, value=1),\n",
       " Bucket(key=2, value=2),\n",
       " Bucket(key=3, value=3),\n",
       " Bucket(key=4, value=4),\n",
       " Bucket(key=5, value=5),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We resize if another element is added\n",
    "d[5] = 5\n",
    "d._data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db82a9a-026f-4d1e-82b6-b80ca81a184d",
   "metadata": {},
   "source": [
    "## Deleting Items\n",
    "\n",
    "We've covered two of our three use cases extensively, but what if we want to delete items from a dictionary? This is more complicated with open addressing as removing the bucket would disrupt our probe sequence. What we're going to do instead is to mark objects as deleted, then have another step to remove the deleted items. Let's update our ``Bucket`` class to reflect this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bc4b2e9-faf7-4976-be68-17737d4b2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Bucket:\n",
    "    key: Hashable\n",
    "    value: Any\n",
    "    is_valid: bool = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a69ddb-d2ed-4058-9dec-4e00467949d7",
   "metadata": {},
   "source": [
    "We also have to update our dictionary class to check if a bucket is deleted before returning it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec13cdec-e43f-41fe-a99d-86a67250acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "\n",
    "    def __init__(self, init_size=8):\n",
    "        self._items = 0\n",
    "        self._size = init_size\n",
    "        self._data: list[Optional[Bucket]] = [None] * self._size\n",
    "        self._reshape_threshold = 2/3\n",
    "\n",
    "    @property\n",
    "    def load_factor(self):\n",
    "        return self._items / self._size\n",
    "        \n",
    "        \n",
    "    def _probes(self, hash_value):\n",
    "        mask = self._size - 1 # used to take modulus fast\n",
    "        perturb = hash_value # used to perturb the probe sequence\n",
    "        probe = hash_value & mask\n",
    "    \n",
    "        while True:\n",
    "            yield probe\n",
    "    \n",
    "            perturb >>= 5\n",
    "            probe = (probe * 5 + perturb + 1) & mask\n",
    "        \n",
    "\n",
    "    def _reshape(self):\n",
    "        self._size <<= 1\n",
    "        new_buckets = [None] * self._size\n",
    "        for bucket in self._data:\n",
    "            if bucket and bucket.is_valid:\n",
    "                h = hash(bucket.key)\n",
    "                for probe in self._probes(h):\n",
    "                    if new_buckets[probe] is None:\n",
    "                        new_buckets[probe] = bucket\n",
    "                        break\n",
    "        self._data = new_buckets\n",
    "        \n",
    "    def __setitem__(self, key, value):\n",
    "        h = hash(key)\n",
    "        new_bucket = Bucket(key, value)\n",
    "        \n",
    "        for probe in self._probes(h):\n",
    "            bucket = self._data[probe]\n",
    "            if bucket is None or not bucket.is_valid:\n",
    "                self._data[probe] = new_bucket\n",
    "                self._items += 1\n",
    "                break\n",
    "            elif bucket.key == new_bucket.key:\n",
    "                self._data[probe] = new_bucket\n",
    "                break\n",
    "\n",
    "        if self.load_factor > self._reshape_threshold:\n",
    "            self._reshape()\n",
    "            \n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        h = hash(item)\n",
    "        for probe in self._probes(h):\n",
    "            bucket = self._data[probe]\n",
    "            if bucket is None:\n",
    "                raise KeyError(item)\n",
    "            elif bucket and bucket.key == item:\n",
    "                return self._data[probe].value\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        h = hash(key)\n",
    "        for probe in self._probes(h):\n",
    "            bucket = self._data[probe]\n",
    "            if bucket is not None and bucket.is_valid and bucket.key == key:\n",
    "                bucket.is_valid = False\n",
    "                self._items -= 1\n",
    "                return\n",
    "        raise KeyError(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5075572-ed37-4c75-a3d3-ec6cbfc153e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bucket(key=5, value=15, is_valid=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bucket(5, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e389027-7fd4-48af-a768-64e02cfc842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "309df889-7281-45e9-9bf0-239e2141d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d8cb1d1-2415-4c56-bcbc-ac600a3f157b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " Bucket(key=1, value=1, is_valid=True),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5365841c-426f-4991-8db5-a80795686333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " Bucket(key=1, value=1, is_valid=False),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d[1]\n",
    "d._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3c056e2-7c38-4a3b-bd03-70d9487cb1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " Bucket(key=9, value='abc', is_valid=True),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[9] = \"abc\"\n",
    "d._data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd43a29e-6b71-49c1-b231-4ea175b3e17d",
   "metadata": {},
   "source": [
    "We've now implemented the three things we used to define a dictionary. But there's one thing left we need to modify. Now that we can delete keys we should also resize the dictionary such that the dictionary _shrinks_ if the load factor falls below some threshold value. That way we aren't using a very large dictionary to store a small number of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83b2e5a5-0ff9-4b54-bd71-d3405fd26481",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary:\n",
    "\n",
    "    def __init__(self, init_size=8):\n",
    "        self._items = 0\n",
    "        self._size = init_size\n",
    "        self._data: list[Optional[Bucket]] = [None] * self._size\n",
    "        self._reshape_threshold_grow = 2/3\n",
    "        self._reshape_threshold_shrink = 1/3\n",
    "\n",
    "    @property\n",
    "    def load_factor(self):\n",
    "        return self._items / self._size\n",
    "        \n",
    "        \n",
    "    def _probes(self, hash_value):\n",
    "        mask = self._size - 1 # used to take modulus fast\n",
    "        perturb = hash_value # used to perturb the probe sequence\n",
    "        probe = hash_value & mask\n",
    "    \n",
    "        while True:\n",
    "            yield probe\n",
    "    \n",
    "            perturb >>= 5\n",
    "            probe = (probe * 5 + perturb + 1) & mask\n",
    "        \n",
    "\n",
    "    def _reshape(self, grow: bool):\n",
    "        if grow:\n",
    "            self._size <<= 1\n",
    "        else:\n",
    "            self._size >>= 1\n",
    "\n",
    "        new_buckets = [None] * self._size\n",
    "        for bucket in self._data:\n",
    "            if bucket and bucket.is_valid:\n",
    "                h = hash(bucket.key)\n",
    "                for probe in self._probes(h):\n",
    "                    if new_buckets[probe] is None:\n",
    "                        new_buckets[probe] = bucket\n",
    "                        break\n",
    "        self._data = new_buckets\n",
    "        \n",
    "    def __setitem__(self, key, value):\n",
    "        h = hash(key)\n",
    "        new_bucket = Bucket(key, value)\n",
    "        \n",
    "        for probe in self._probes(h):\n",
    "            bucket = self._data[probe]\n",
    "            if bucket is None or not bucket.is_valid:\n",
    "                self._data[probe] = new_bucket\n",
    "                self._items += 1\n",
    "                break\n",
    "            elif bucket.key == new_bucket.key:\n",
    "                self._data[probe] = new_bucket\n",
    "                break\n",
    "\n",
    "        if self.load_factor > self._reshape_threshold_grow:\n",
    "            self._reshape(grow=True)\n",
    "        elif self.load_factor < self._reshape_threshold_shrink:\n",
    "            self._reshape(grow=False)\n",
    "            \n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        h = hash(item)\n",
    "        for probe in self._probes(h):\n",
    "            bucket = self._data[probe]\n",
    "            if bucket is None:\n",
    "                raise KeyError(item)\n",
    "            elif bucket and bucket.key == item:\n",
    "                return self._data[probe].value\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        h = hash(key)\n",
    "        for probe in self._probes(h):\n",
    "            bucket = self._data[probe]\n",
    "            if bucket is not None and bucket.is_valid and bucket.key == key:\n",
    "                bucket.is_valid = False\n",
    "                self._items -= 1\n",
    "                return\n",
    "        raise KeyError(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e42c929-3c43-42c6-80d1-1386640ca3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key=0, value=0, is_valid=True),\n",
       " Bucket(key=1, value=1, is_valid=True),\n",
       " Bucket(key=2, value=2, is_valid=True),\n",
       " Bucket(key=3, value=3, is_valid=True),\n",
       " Bucket(key=4, value=4, is_valid=True),\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Dictionary()\n",
    "\n",
    "for i in range(5):\n",
    "    d[i] = i\n",
    "d._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12ee7076-b9ea-4a1d-a97d-c5778f010d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key=0, value=0, is_valid=True),\n",
       " Bucket(key=1, value=1, is_valid=True),\n",
       " Bucket(key=2, value=2, is_valid=True),\n",
       " Bucket(key=3, value=3, is_valid=True),\n",
       " Bucket(key=4, value=4, is_valid=True),\n",
       " Bucket(key=5, value=5, is_valid=True),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[5] = 5\n",
    "d._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b786d5cd-0d97-4691-af14-4b6d9572c0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key=0, value=0, is_valid=True),\n",
       " Bucket(key=1, value=1, is_valid=False),\n",
       " Bucket(key=2, value=2, is_valid=False),\n",
       " Bucket(key=3, value=3, is_valid=True),\n",
       " Bucket(key=4, value=4, is_valid=True),\n",
       " Bucket(key=5, value=5, is_valid=True),\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d[1]\n",
    "del d[2]\n",
    "d._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8db349fb-6514-4e8e-a0eb-f0b0c0c97d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucket(key=0, value=0, is_valid=True),\n",
       " None,\n",
       " None,\n",
       " Bucket(key=3, value=3, is_valid=True),\n",
       " Bucket(key=4, value=4, is_valid=True),\n",
       " Bucket(key=5, value=5, is_valid=True),\n",
       " None,\n",
       " Bucket(key=7, value=15, is_valid=True)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[7] = 15\n",
    "d._data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf63559-6368-4917-985a-00a1889a240e",
   "metadata": {},
   "source": [
    "# How Python does it differently: Dense Tables\n",
    "\n",
    "So far we've explored how a hashtable is _usually_ implemented. We've implemented our hashtable as a list of ``Bucket`` objects.  Since Python 3.6 the layout of a hashtable has changed. A dictionary like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26849831-5c69-44b6-bfad-fc1dfe391b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"one\": 1, \"two\": 2, \"three\": 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1772839f-d088-4070-9963-fd1baf0c8647",
   "metadata": {},
   "source": [
    "Would be represented roughly like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93038d27-483d-4687-8c10-c43b150393ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_table = [\n",
    "    ('--', '--', '--'),\n",
    "    (542403711206072985, 'two', 2),\n",
    "    ('--', '--', '--'),\n",
    "    (4677866115915370763, 'three', 3),\n",
    "    ('--', '--', '--'),\n",
    "    (-1182584047114089363, 'one', 1),\n",
    "    ('--', '--', '--'),\n",
    "    ('--', '--', '--')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c7fc53-8e12-40d2-932c-6043c5309919",
   "metadata": {},
   "source": [
    "However this isn't optimal because of how Python stores objects, instead Python uses the following layout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d41b0a0c-3b5a-4301-9a98-82582747bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_table = [None, 1, None, 2, None, 0, None, None]\n",
    "entries = [\n",
    "    (-1182584047114089363, 'one', 1),\n",
    "    (542403711206072985, 'two', 2),\n",
    "    (4677866115915370763, 'three', 3),\n",
    "    ('--', '--', '--'),\n",
    "    ('--', '--', '--'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b7cd8-545c-4bfb-908a-b5e102d2afcb",
   "metadata": {},
   "source": [
    "In this layout the hashtable only stores indexes to an entries array. Each index takes 1, 2, 4 or 8 bytes depending on the size of the dictionary. Either way, that much less than the 24 bytes taken by our previous Python object! This means that we save a lot of space in the hashtable itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a2b1b-1fee-4c93-a9fb-6e470e6ac953",
   "metadata": {},
   "source": [
    "# More Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631fd793-25bb-4395-921d-3c92a9b5a1ed",
   "metadata": {},
   "source": [
    "## Designing a _GOOD_ hash function\n",
    "\n",
    "Up to this point we've simply used Python's inbuilt function ``hash`` to compute the hashes for our hash table. But how do we know if this is a _good_ hash function? What does it even mean for a hash function to be good? Let's try to answer some of these questions!\n",
    "\n",
    "### Some properties we might want in a good hash function\n",
    "\n",
    "* Uniform Distribution\n",
    "* One-Way Functions\n",
    "* Fast\n",
    "\n",
    "It turns out that designing a function with all of these properties is hard. We'll have to make compromises somewhere. They skill becomes knowing which compromises are right for your application.\n",
    "\n",
    "### Randomly Generated Hash functions\n",
    "\n",
    "In theory randomly generated hash functions meet all our requirements but are rarely, if ever used in practice. Why is this? It's because the use too much memory. As the generated hash is random, the only way to get the same hash is to store every hash in memory. This uses to much memory to be used in practice.\n",
    "\n",
    "### Non-cryptographic hash functions\n",
    "\n",
    "There are many, many, many possible non-cryptographic hash functions design for hashtables. One of them is FVN-1a. This function:\n",
    "\n",
    "1. combines the byte with the current hash value (xor)\n",
    "2. mixes the current hash value (multiplication)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66967634-f3c0-43a2-9a5a-fe204a714fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFSET_BASIS = 2166136261\n",
    "FNV_PRIME = 16777619\n",
    "HASH_SIZE = 2 ** 32\n",
    "\n",
    "def fvn1a(data: bytes) -> int:\n",
    "    h = OFFSET_BASIS\n",
    "    for byte in data:\n",
    "        h = h ^ byte\n",
    "        h = (h * FNV_PRIME) % HASH_SIZE\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726cc43c-a3a5-4210-bb09-f3e01568b6de",
   "metadata": {},
   "source": [
    "Non-cryptographic hash functions perform _really_ well when acting on \"normal\" data, the drawback is that it's possible to generate adversarial inputs to the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaebfab-7c86-42f0-a96d-3cc6d89cd870",
   "metadata": {},
   "source": [
    "### Universal hashing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
